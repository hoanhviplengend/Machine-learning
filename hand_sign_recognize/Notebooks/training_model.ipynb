{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "101e43f871bb657c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:55:09.206634Z",
     "start_time": "2024-10-17T16:55:06.576742Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:55:10.077617Z",
     "start_time": "2024-10-17T16:55:10.068648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "checkpoint = ModelCheckpoint('../Scripts/best_model_lenet.h5', monitor='val_loss', save_best_only=True, mode='min')"
   ],
   "id": "f2872ebc1689d8e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a51eed293ef95c8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:55:28.434280Z",
     "start_time": "2024-10-17T16:55:28.430294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    print(\"Có GPU sẵn sàng.\")\n",
    "else:\n",
    "    print(\"Không tìm thấy GPU.\")\n",
    "    sys.exit()"
   ],
   "id": "26d308b656fd0afa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có GPU sẵn sàng.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:55:31.276458Z",
     "start_time": "2024-10-17T16:55:31.264459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(data_dir)  # Lấy tên các lớp từ thư mục\n",
    "\n",
    "    for label in class_names:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        if os.path.isdir(class_dir):  # Kiểm tra xem đây có phải là thư mục không\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg'):  # Kiểm tra định dạng tệp\n",
    "                    img_path = os.path.join(class_dir, filename)\n",
    "                    image = Image.open(img_path).convert('RGB')  # Chuyển đổi thành ảnh RGB\n",
    "                    image = image.resize((32, 32))  # Thay đổi kích thước ảnh\n",
    "                    images.append(np.array(image))\n",
    "                    labels.append(class_names.index(label))  # Gán nhãn lớp\n",
    "\n",
    "    return np.array(images), to_categorical(np.array(labels), num_classes=36)  # Trả về mảng NumPy của ảnh và nhãn"
   ],
   "id": "1afca6b3593ba457",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:55:51.437980Z",
     "start_time": "2024-10-17T16:55:33.226391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dir = r'..\\Data\\Gesture Image Pre-Processed Data'\n",
    "test_dir = r'..\\Data\\Gesture Image Pre-Processed Data - Test'\n",
    "\n",
    "# Tải dữ liệu\n",
    "X_train, Y_train = load_data(train_dir)\n",
    "X_test, Y_test = load_data(test_dir)"
   ],
   "id": "99c6e6f54e9aa150",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:56:20.705065Z",
     "start_time": "2024-10-17T16:55:54.632867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Lớp tích chập đầu tiên\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'))  # 3 kênh màu\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "# Lớp tích chập thứ hai\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "# Lớp tích chập thứ ba\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D())\n",
    "\n",
    "# Chuyển đổi đặc trưng thành vector\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))  # Tăng số lượng nơ-ron\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để giảm overfitting\n",
    "\n",
    "model.add(Dense(256, activation='relu'))  # Tăng số lượng nơ-ron\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để giảm overfitting\n",
    "\n",
    "model.add(Dense(128, activation='relu'))  # Tăng số lượng nơ-ron\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để giảm overfitting\n",
    "\n",
    "# Lớp output với số lớp tương ứng\n",
    "model.add(Dense(36, activation='softmax'))  # 36 lớp\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_train, Y_train, epochs=50, validation_data=(X_test, Y_test), batch_size=64,\n",
    "                callbacks=[checkpoint, reduce_lr, early_stop])\n",
    "\n",
    "# Lưu mô hình\n",
    "#model.save('../Scripts/hand_sign_recognition_lenet5.h5')"
   ],
   "id": "6484810c91778604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "844/844 [==============================] - 9s 9ms/step - loss: 0.7230 - accuracy: 0.7917 - val_loss: 3.8890e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.0212 - val_accuracy: 0.9962 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "194/844 [=====>........................] - ETA: 5s - loss: 0.0596 - accuracy: 0.9866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 40\u001B[0m\n\u001B[0;32m     37\u001B[0m early_stop \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Huấn luyện mô hình\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_lr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stop\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Lưu mô hình\u001B[39;00m\n\u001B[0;32m     44\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../Scripts/hand_sign_recognition_lenet5.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\engine\\training.py:1413\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1411\u001B[0m   context\u001B[38;5;241m.\u001B[39masync_wait()\n\u001B[0;32m   1412\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs  \u001B[38;5;66;03m# No error, now safe to assign to logs.\u001B[39;00m\n\u001B[1;32m-> 1413\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m \u001B[43mdata_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_increment\u001B[49m\n\u001B[0;32m   1414\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(end_step, logs)\n\u001B[0;32m   1415\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1268\u001B[0m, in \u001B[0;36mDataHandler.step_increment\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1265\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m steps_remaining\n\u001B[0;32m   1266\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution\u001B[38;5;241m.\u001B[39massign(original_spe)\n\u001B[1;32m-> 1268\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_increment\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1270\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001B[39;00m\n\u001B[0;32m   1271\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step_increment\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss cho tập huấn luyện\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss (Train)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (Validation)')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy cho tập huấn luyện\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy (Train)')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy (Validation)')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "5c16be002c0b29b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
